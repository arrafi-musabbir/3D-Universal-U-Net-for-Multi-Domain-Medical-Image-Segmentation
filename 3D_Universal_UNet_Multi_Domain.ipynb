{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###  loading dataset from drive"
      ],
      "metadata": {
        "id": "Ch9zQizrSkiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFkHrVup9jjL",
        "outputId": "93cffc6d-ab9c-4201-ea0c-a759f46a8004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/MSD/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DutLyGpRTHQB",
        "outputId": "c73924e9-65b2-4462-9d63-45b6628c807c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "license.txt\t\tTask03_Liver.tar\tTask06_Lung.tar\t\t  Task09_Spleen.tar\n",
            "Task01_BrainTumour.tar\tTask04_Hippocampus.tar\tTask07_Pancreas.tar\t  Task10_Colon.tar\n",
            "Task02_Heart.tar\tTask05_Prostate.tar\tTask08_HepaticVessel.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cloning github repo"
      ],
      "metadata": {
        "id": "_Z0DqiHESqP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0i3-2by9XJ0",
        "outputId": "60d822d4-3301-45ac-fa60-2210d84d7bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation'...\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 219 (delta 55), reused 58 (delta 25), pack-reused 108\u001b[K\n",
            "Receiving objects: 100% (219/219), 2.47 MiB | 771.00 KiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arrafi-musabbir/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpleitk\n",
        "!pip install tensorboardx\n",
        "!pip install -q batchgenerators==0.20.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCYd7htzT4nY",
        "outputId": "b98387a9-6144-429f-8d47-323307af267b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simpleitk\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: simpleitk\n",
            "Successfully installed simpleitk-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create `dataset` directory"
      ],
      "metadata": {
        "id": "MIAGxGWqS1hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset"
      ],
      "metadata": {
        "id": "j1q9zAInK--J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extract `.tar` files to dataset directory"
      ],
      "metadata": {
        "id": "aNHhRkT5S1BC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "P4-OeUW0Bpl4"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/drive/MyDrive/MSD/Task02_Heart.tar -C /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf /content/drive/MyDrive/MSD/Task04_Hippocampus.tar -C /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset"
      ],
      "metadata": {
        "id": "eDjKZKrGTC-n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extracted datasets"
      ],
      "metadata": {
        "id": "x4sZGRdTTzjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53GU-izPTwit",
        "outputId": "cb5cc52c-9600-4801-e8eb-23088f304f34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task02_Heart  Task04_Hippocampus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## remove unwanted files\n",
        "%cd /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset\n",
        "!find  . -name '.*' -exec rm {} \\;\n",
        "!ls -la  /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHk7ub29VcpV",
        "outputId": "dd144f82-9e9c-4809-e859-97649b12235d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset\n",
            "rm: cannot remove '.': Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### changing current directory to the cloned directory"
      ],
      "metadata": {
        "id": "scK_4GAlTqN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uN_U6_yMWZJ",
        "outputId": "fda489b8-b09e-4ab0-a75f-e231ae0da95f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### explore extracted datasets"
      ],
      "metadata": {
        "id": "19EyV5PDd9J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_explore.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4WXDuHfeNcI",
        "outputId": "a614bee6-dfe7-47af-c420-eeb0cd83172a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: data_explore.py [-h] [--task TASK] [--root ROOT]\n",
            "\n",
            "msd\n",
            "\n",
            "options:\n",
            "  -h, --help   show this help message and exit\n",
            "  --task TASK\n",
            "  --root ROOT  path to save msd_meta.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd-mlypI9ij6",
        "outputId": "0e654013-6b2c-4e64-df75-5a5ad8e45e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation\n",
            "task..., patID...\n",
            "100% 2/2 [00:00<00:00, 435.30it/s]\n",
            "100% 24/24 [00:00<00:00, 581868.76it/s]\n",
            "task:   0% 0/2 [00:00<?, ?it/s]\n",
            "f_path:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "f_path:   5% 1/20 [00:00<00:07,  2.52it/s]\u001b[A\n",
            "f_path:  10% 2/20 [00:00<00:07,  2.34it/s]\u001b[A\n",
            "f_path:  15% 3/20 [00:01<00:07,  2.30it/s]\u001b[A\n",
            "f_path:  20% 4/20 [00:01<00:06,  2.48it/s]\u001b[A\n",
            "f_path:  25% 5/20 [00:02<00:06,  2.37it/s]\u001b[A\n",
            "f_path:  30% 6/20 [00:02<00:05,  2.44it/s]\u001b[A\n",
            "f_path:  35% 7/20 [00:02<00:04,  2.72it/s]\u001b[A\n",
            "f_path:  40% 8/20 [00:03<00:04,  2.90it/s]\u001b[A\n",
            "f_path:  45% 9/20 [00:03<00:03,  3.02it/s]\u001b[A\n",
            "f_path:  50% 10/20 [00:03<00:03,  3.20it/s]\u001b[A\n",
            "f_path:  55% 11/20 [00:03<00:02,  3.13it/s]\u001b[A\n",
            "f_path:  60% 12/20 [00:04<00:02,  3.25it/s]\u001b[A\n",
            "f_path:  65% 13/20 [00:04<00:02,  3.33it/s]\u001b[A\n",
            "f_path:  70% 14/20 [00:04<00:01,  3.29it/s]\u001b[A\n",
            "f_path:  75% 15/20 [00:05<00:01,  3.67it/s]\u001b[A\n",
            "f_path:  80% 16/20 [00:05<00:01,  3.72it/s]\u001b[A\n",
            "f_path:  85% 17/20 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "f_path:  90% 18/20 [00:05<00:00,  3.44it/s]\u001b[A\n",
            "f_path:  95% 19/20 [00:06<00:00,  3.58it/s]\u001b[A\n",
            "f_path: 100% 20/20 [00:06<00:00,  3.09it/s]\n",
            "task:  50% 1/2 [00:06<00:06,  6.47s/it]\n",
            "f_path:   0% 0/260 [00:00<?, ?it/s]\u001b[A\n",
            "f_path:   4% 11/260 [00:00<00:02, 105.23it/s]\u001b[A\n",
            "f_path:   8% 22/260 [00:00<00:02, 103.98it/s]\u001b[A\n",
            "f_path:  13% 33/260 [00:00<00:02, 100.80it/s]\u001b[A\n",
            "f_path:  17% 44/260 [00:00<00:02, 99.33it/s] \u001b[A\n",
            "f_path:  21% 54/260 [00:00<00:02, 84.58it/s]\u001b[A\n",
            "f_path:  25% 64/260 [00:00<00:02, 87.93it/s]\u001b[A\n",
            "f_path:  28% 74/260 [00:00<00:02, 89.92it/s]\u001b[A\n",
            "f_path:  32% 84/260 [00:00<00:01, 92.52it/s]\u001b[A\n",
            "f_path:  36% 94/260 [00:01<00:01, 85.96it/s]\u001b[A\n",
            "f_path:  40% 103/260 [00:01<00:01, 83.08it/s]\u001b[A\n",
            "f_path:  43% 113/260 [00:01<00:01, 87.01it/s]\u001b[A\n",
            "f_path:  47% 123/260 [00:01<00:01, 86.74it/s]\u001b[A\n",
            "f_path:  51% 132/260 [00:01<00:01, 86.42it/s]\u001b[A\n",
            "f_path:  55% 142/260 [00:01<00:01, 88.35it/s]\u001b[A\n",
            "f_path:  59% 153/260 [00:01<00:01, 92.46it/s]\u001b[A\n",
            "f_path:  63% 163/260 [00:01<00:01, 92.61it/s]\u001b[A\n",
            "f_path:  67% 173/260 [00:01<00:00, 92.40it/s]\u001b[A\n",
            "f_path:  71% 184/260 [00:02<00:00, 96.98it/s]\u001b[A\n",
            "f_path:  75% 194/260 [00:02<00:00, 97.81it/s]\u001b[A\n",
            "f_path:  78% 204/260 [00:02<00:00, 97.15it/s]\u001b[A\n",
            "f_path:  82% 214/260 [00:02<00:00, 97.30it/s]\u001b[A\n",
            "f_path:  86% 224/260 [00:02<00:00, 96.60it/s]\u001b[A\n",
            "f_path:  90% 234/260 [00:02<00:00, 97.02it/s]\u001b[A\n",
            "f_path:  94% 244/260 [00:02<00:00, 97.70it/s]\u001b[A\n",
            "f_path: 100% 260/260 [00:02<00:00, 93.44it/s]\n",
            "task: 100% 2/2 [00:09<00:00,  4.63s/it]\n"
          ]
        }
      ],
      "source": [
        "!python data_explore.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocess datasets"
      ],
      "metadata": {
        "id": "3SSqeu-LWIYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using maximum number of cores available\n",
        "import multiprocessing\n",
        "available_cores = multiprocessing.cpu_count()\n",
        "\n",
        "!python preprocess_taskSep.py  --nProc available_cores --tasks Task02_Heart Task04_Hippocampus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNYJbDAQMSbX",
        "outputId": "faf9cc97-9d34-4dcd-86b4-f98a13b9bc32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/2 [00:00<?, ?it/s]Task02_Heart\n",
            "file path is :/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset/Task02_Heart/dataset.json\n",
            "ids[0]:la_003.nii.gz, current time:20231222_1146\n",
            "ids[0]:la_001.nii.gz, current time:20231222_1146\n",
            "NOT fusing cancer to organ!\n",
            " 50% 1/2 [02:45<02:45, 165.03s/it]Task04_Hippocampus\n",
            "file path is :/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset/Task04_Hippocampus/dataset.json\n",
            "ids[0]:hippocampus_001.nii.gz, current time:20231222_1148\n",
            "ids[0]:hippocampus_002.nii.gz, current time:20231222_1148\n",
            "NOT fusing cancer to organ!\n",
            "100% 2/2 [03:09<00:00, 94.70s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train the model with adapters"
      ],
      "metadata": {
        "id": "FMEOkzN1XmP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZiVLacRYGWs",
        "outputId": "b200c626-b06d-4e9e-f3cb-73ba55963745"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## to see available arguments\n",
        "!python train_model_wt_adapters.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fzjIgW_XpvV",
        "outputId": "57137ddd-0a2f-47ab-f763-a6db482698ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train_model_wt_adapters.py [-h] [--tasks TASKS [TASKS ...]] [--trainMode TRAINMODE]\n",
            "                                  [--module MODULE] [--ckp CKP] [--resume_ckp RESUME_CKP]\n",
            "                                  [--resume_epoch RESUME_EPOCH] [--fold FOLD] [--model MODEL]\n",
            "                                  [--out_tag OUT_TAG] [--base_outChans BASE_OUTCHANS]\n",
            "                                  [--predict PREDICT] [--pred_epoch PRED_EPOCH]\n",
            "\n",
            "u2net\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --tasks TASKS [TASKS ...]\n",
            "                        Task(s) to be trained\n",
            "  --trainMode TRAINMODE\n",
            "                        Task adaptation mode\n",
            "  --module MODULE       specific module type: series_adapter, parallel_adapter, separable_adapter\n",
            "  --ckp CKP             dir to load ckp for transfer learning\n",
            "  --resume_ckp RESUME_CKP\n",
            "                        dir to load ckp for evaluation or training\n",
            "  --resume_epoch RESUME_EPOCH\n",
            "                        epoch of resume_ckp\n",
            "  --fold FOLD           fold index\n",
            "  --model MODEL         model name\n",
            "  --out_tag OUT_TAG     output dir tag\n",
            "  --base_outChans BASE_OUTCHANS\n",
            "                        base_outChans\n",
            "  --predict PREDICT     Run prediction\n",
            "  --pred_epoch PRED_EPOCH\n",
            "                        Run prediction with ckp of epoch num\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_model_wt_adapters.py --module parallel_adapter --tasks Task02_Heart Task04_Hippocampus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtVO-us4P6BT",
        "outputId": "abc44df8-c986-4d59-c94e-ea1e5c767aeb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file path is :/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset/Task02_Heart/dataset.json\n",
            "file path is :/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/dataset/Task04_Hippocampus/dataset.json\n",
            "\u001b[32m[1222 12:15:20 @logger.py:135]\u001b[0m Directory '/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/results/res_u2net3d_universal/Task02_Heart_Task04_Hippocampus/train_log/logger' backuped to '/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/results/res_u2net3d_universal/Task02_Heart_Task04_Hippocampus/train_log/logger1222-121520'\n",
            "\u001b[32m[1222 12:15:20 @logger.py:90]\u001b[0m Argv: train_model_wt_adapters.py --module parallel_adapter --tasks Task02_Heart Task04_Hippocampus\n",
            "\u001b[32m[1222 12:15:20 @train_model_wt_adapters.py:95]\u001b[0m --------------------------------Training for universal: Task02_Heart_Task04_Hippocampus--------------------------------\n",
            "\u001b[32m[1222 12:15:20 @u2net3d.py:298]\u001b[0m ------- base_outChans is 16\n",
            "\u001b[32m[1222 12:15:21 @train_model_wt_adapters.py:156]\u001b[0m ------------------------------------------------------------------\n",
            "\u001b[32m[1222 12:15:21 @train_model_wt_adapters.py:157]\u001b[0m ------------  train model with adapters from scratch -------------\n",
            "\u001b[32m[1222 12:15:21 @train_model_wt_adapters.py:158]\u001b[0m ------------------------------------------------------------------\n",
            "\u001b[32m[1222 12:15:22 @train.py:199]\u001b[0m   + model num_params: 35400771\n",
            "DataParallel(\n",
            "  (module): u2net3d(\n",
            "    (in_tr_list): ModuleList(\n",
            "      (0-1): 2 x InputTransition(\n",
            "        (op1): Sequential(\n",
            "          (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (1): Sequential(\n",
            "            (0): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "            (1): LeakyReLU(negative_slope=0.01)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down_blocks): ModuleList(\n",
            "      (0): DownBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): DownBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): DownBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): DownBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (4): DownBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (5): DownBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (down_samps): ModuleList(\n",
            "      (0): DownSample(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): DownSample(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): DownSample(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): DownSample(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (4): DownSample(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (up_samps): ModuleList(\n",
            "      (0): UnetUpsample(\n",
            "        (upsamples): ModuleList(\n",
            "          (0-1): 2 x Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (op): conv_unit(\n",
            "          (conv): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): UnetUpsample(\n",
            "        (upsamples): ModuleList(\n",
            "          (0-1): 2 x Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (op): conv_unit(\n",
            "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): UnetUpsample(\n",
            "        (upsamples): ModuleList(\n",
            "          (0-1): 2 x Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (op): conv_unit(\n",
            "          (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): UnetUpsample(\n",
            "        (upsamples): ModuleList(\n",
            "          (0-1): 2 x Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (op): conv_unit(\n",
            "          (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (4): UnetUpsample(\n",
            "        (upsamples): ModuleList(\n",
            "          (0-1): 2 x Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (op): conv_unit(\n",
            "          (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (up_blocks): ModuleList(\n",
            "      (0): UpBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): UpBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): UpBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): UpBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (4): UpBlock(\n",
            "        (op1): conv_unit(\n",
            "          (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act1): LeakyReLU(negative_slope=0.01)\n",
            "        (op2): conv_unit(\n",
            "          (conv): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          (adapOps): ModuleList(\n",
            "            (0-1): 2 x conv1x1(\n",
            "              (op1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (op): ModuleList(\n",
            "            (0-1): 2 x InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (act2): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (dSupers): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): DeepSupervision(\n",
            "          (op1): Sequential(\n",
            "            (0): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            (1): Sequential(\n",
            "              (0): InstanceNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "              (1): LeakyReLU(negative_slope=0.01)\n",
            "            )\n",
            "          )\n",
            "          (op2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (1): DeepSupervision(\n",
            "          (op1): Sequential(\n",
            "            (0): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            (1): Sequential(\n",
            "              (0): InstanceNorm3d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "              (1): LeakyReLU(negative_slope=0.01)\n",
            "            )\n",
            "          )\n",
            "          (op2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "      )\n",
            "      (1): ModuleList(\n",
            "        (0): DeepSupervision(\n",
            "          (op1): Sequential(\n",
            "            (0): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            (1): Sequential(\n",
            "              (0): InstanceNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "              (1): LeakyReLU(negative_slope=0.01)\n",
            "            )\n",
            "          )\n",
            "          (op2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "        (1): DeepSupervision(\n",
            "          (op1): Sequential(\n",
            "            (0): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "            (1): Sequential(\n",
            "              (0): InstanceNorm3d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "              (1): LeakyReLU(negative_slope=0.01)\n",
            "            )\n",
            "          )\n",
            "          (op2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (out_tr_list): ModuleList(\n",
            "      (0): OutputTransition(\n",
            "        (conv1): Conv3d(16, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "      )\n",
            "      (1): OutputTransition(\n",
            "        (conv1): Conv3d(16, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[1222 12:15:22 @train.py:252]\u001b[0m start epoch: 1\n",
            "\u001b[32m[1222 12:15:22 @train.py:256]\u001b[0m     ----- training epoch 1 -----\n",
            "universal: epoch1:   0% 0/300 [00:00<?, ?it/s]\u001b[32m[1222 12:15:22 @train.py:104]\u001b[0m Task02_Heart self.trainQueue size = 0, filling....(start time:20231222_1215)\n",
            "\u001b[32m[1222 12:16:00 @train.py:109]\u001b[0m Task02_Heart time to fill self.trainQueue: 38\n",
            "\u001b[32m[1222 12:16:17 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:00:54 -----\n",
            "universal: epoch1:   0% 1/300 [01:51<9:15:19, 111.43s/it]\u001b[32m[1222 12:17:14 @data_utils.py:184]\u001b[0m Task04_Hippocampus queue is full, size=4, time waited for full:67\n",
            "\u001b[32m[1222 12:17:15 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:01:52 -----\n",
            "universal: epoch1:   1% 2/300 [01:56<4:02:23, 48.81s/it] \u001b[32m[1222 12:17:20 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:01:58 -----\n",
            "universal: epoch1:   1% 3/300 [01:59<2:18:38, 28.01s/it]\u001b[32m[1222 12:17:24 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:02:01 -----\n",
            "universal: epoch1:   1% 4/300 [02:03<1:30:51, 18.42s/it]\u001b[32m[1222 12:17:27 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:02:04 -----\n",
            "\u001b[32m[1222 12:17:27 @data_utils.py:184]\u001b[0m Task02_Heart queue is full, size=5, time waited for full:8\n",
            "\u001b[32m[1222 12:17:27 @data_utils.py:184]\u001b[0m Task02_Heart queue is full, size=5, time waited for full:37\n",
            "universal: epoch1:   2% 5/300 [02:06<1:03:11, 12.85s/it]\u001b[32m[1222 12:17:30 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:02:08 -----\n",
            "universal: epoch1:   2% 6/300 [02:10<47:41,  9.73s/it]  \u001b[32m[1222 12:17:34 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:02:11 -----\n",
            "universal: epoch1:   2% 7/300 [02:13<37:13,  7.62s/it]\u001b[32m[1222 12:17:37 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1217)\n",
            "\u001b[32m[1222 12:17:52 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 15\n",
            "\u001b[32m[1222 12:17:54 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:02:31 -----\n",
            "universal: epoch1:   3% 8/300 [02:33<56:08, 11.54s/it]\u001b[32m[1222 12:17:58 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:02:36 -----\n",
            "universal: epoch1:   3% 9/300 [02:37<45:17,  9.34s/it]\u001b[32m[1222 12:18:00 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1218)\n",
            "\u001b[32m[1222 12:18:16 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 15\n",
            "\u001b[32m[1222 12:18:16 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:02:54 -----\n",
            "universal: epoch1:   3% 10/300 [02:56<58:32, 12.11s/it]\u001b[32m[1222 12:18:20 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:02:57 -----\n",
            "universal: epoch1:   4% 11/300 [02:59<45:28,  9.44s/it]\u001b[32m[1222 12:18:22 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1218)\n",
            "\u001b[32m[1222 12:18:38 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:18:39 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:03:17 -----\n",
            "universal: epoch1:   4% 12/300 [03:18<59:58, 12.49s/it]\u001b[32m[1222 12:18:44 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:03:21 -----\n",
            "universal: epoch1:   4% 13/300 [03:23<48:03, 10.05s/it]\u001b[32m[1222 12:18:47 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1218)\n",
            "\u001b[32m[1222 12:19:02 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 15\n",
            "\u001b[32m[1222 12:19:04 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:03:41 -----\n",
            "universal: epoch1:   5% 14/300 [03:43<1:02:03, 13.02s/it]\u001b[32m[1222 12:19:07 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:03:44 -----\n",
            "universal: epoch1:   5% 15/300 [03:46<47:28, 10.00s/it]  \u001b[32m[1222 12:19:09 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1219)\n",
            "\u001b[32m[1222 12:19:25 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:19:26 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:04:04 -----\n",
            "universal: epoch1:   5% 16/300 [04:05<1:00:50, 12.85s/it]\u001b[32m[1222 12:19:29 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:04:07 -----\n",
            "universal: epoch1:   6% 17/300 [04:08<46:56,  9.95s/it]  \u001b[32m[1222 12:19:33 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1219)\n",
            "\u001b[32m[1222 12:19:50 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 17\n",
            "\u001b[32m[1222 12:19:51 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:04:29 -----\n",
            "universal: epoch1:   6% 18/300 [04:30<1:03:34, 13.53s/it]\u001b[32m[1222 12:19:55 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:04:33 -----\n",
            "universal: epoch1:   6% 19/300 [04:34<50:12, 10.72s/it]  \u001b[32m[1222 12:19:58 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1219)\n",
            "\u001b[32m[1222 12:20:16 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 18\n",
            "\u001b[32m[1222 12:20:17 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:04:54 -----\n",
            "universal: epoch1:   7% 20/300 [04:56<1:05:01, 13.93s/it]\u001b[32m[1222 12:20:20 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:04:58 -----\n",
            "universal: epoch1:   7% 21/300 [04:59<49:59, 10.75s/it]  \u001b[32m[1222 12:20:23 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1220)\n",
            "\u001b[32m[1222 12:20:40 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 17\n",
            "\u001b[32m[1222 12:20:42 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:05:19 -----\n",
            "universal: epoch1:   7% 22/300 [05:21<1:05:00, 14.03s/it]\u001b[32m[1222 12:20:45 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:05:23 -----\n",
            "universal: epoch1:   8% 23/300 [05:24<50:04, 10.85s/it]  \u001b[32m[1222 12:20:48 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1220)\n",
            "\u001b[32m[1222 12:21:04 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:21:05 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:05:42 -----\n",
            "universal: epoch1:   8% 24/300 [05:44<1:01:40, 13.41s/it]\u001b[32m[1222 12:21:08 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:05:46 -----\n",
            "universal: epoch1:   8% 25/300 [05:47<47:48, 10.43s/it]  \u001b[32m[1222 12:21:10 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1221)\n",
            "\u001b[32m[1222 12:21:25 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 15\n",
            "\u001b[32m[1222 12:21:26 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:06:03 -----\n",
            "universal: epoch1:   9% 26/300 [06:05<57:51, 12.67s/it]\u001b[32m[1222 12:21:30 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:06:08 -----\n",
            "universal: epoch1:   9% 27/300 [06:09<46:24, 10.20s/it]\u001b[32m[1222 12:21:33 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1221)\n",
            "\u001b[32m[1222 12:21:49 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:21:51 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:06:28 -----\n",
            "universal: epoch1:   9% 28/300 [06:30<59:54, 13.22s/it]\u001b[32m[1222 12:21:54 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:06:32 -----\n",
            "universal: epoch1:  10% 29/300 [06:33<46:24, 10.28s/it]\u001b[32m[1222 12:21:57 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1221)\n",
            "\u001b[32m[1222 12:22:13 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:22:13 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:06:51 -----\n",
            "universal: epoch1:  10% 30/300 [06:53<58:37, 13.03s/it]\u001b[32m[1222 12:22:16 @train.py:104]\u001b[0m Task02_Heart self.trainQueue size = 0, filling....(start time:20231222_1222)\n",
            "\u001b[32m[1222 12:22:25 @train.py:109]\u001b[0m Task02_Heart time to fill self.trainQueue: 9\n",
            "\u001b[32m[1222 12:22:26 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:07:03 -----\n",
            "universal: epoch1:  10% 31/300 [07:05<57:23, 12.80s/it]\u001b[32m[1222 12:22:28 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1222)\n",
            "\u001b[32m[1222 12:22:36 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 8\n",
            "\u001b[32m[1222 12:22:38 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:07:15 -----\n",
            "universal: epoch1:  11% 32/300 [07:17<55:54, 12.52s/it]\u001b[32m[1222 12:22:41 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:07:19 -----\n",
            "universal: epoch1:  11% 33/300 [07:21<44:01,  9.90s/it]\u001b[32m[1222 12:22:44 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1222)\n",
            "\u001b[32m[1222 12:23:01 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 17\n",
            "\u001b[32m[1222 12:23:02 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:07:39 -----\n",
            "universal: epoch1:  11% 34/300 [07:41<57:41, 13.01s/it]\u001b[32m[1222 12:23:04 @train.py:104]\u001b[0m Task02_Heart self.trainQueue size = 0, filling....(start time:20231222_1223)\n",
            "\u001b[32m[1222 12:23:07 @train.py:109]\u001b[0m Task02_Heart time to fill self.trainQueue: 3\n",
            "\u001b[32m[1222 12:23:08 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:07:45 -----\n",
            "universal: epoch1:  12% 35/300 [07:47<48:26, 10.97s/it]\u001b[32m[1222 12:23:11 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1223)\n",
            "\u001b[32m[1222 12:23:24 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 13\n",
            "\u001b[32m[1222 12:23:25 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:08:03 -----\n",
            "universal: epoch1:  12% 36/300 [08:05<57:00, 12.96s/it]\u001b[32m[1222 12:23:29 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:08:07 -----\n",
            "universal: epoch1:  12% 37/300 [08:08<44:30, 10.15s/it]\u001b[32m[1222 12:23:31 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1223)\n",
            "\u001b[32m[1222 12:23:48 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:23:49 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:08:26 -----\n",
            "universal: epoch1:  13% 38/300 [08:28<56:32, 12.95s/it]\u001b[32m[1222 12:23:52 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:08:29 -----\n",
            "universal: epoch1:  13% 39/300 [08:31<43:28,  9.99s/it]\u001b[32m[1222 12:23:54 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1223)\n",
            "\u001b[32m[1222 12:24:10 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 16\n",
            "\u001b[32m[1222 12:24:11 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:08:48 -----\n",
            "universal: epoch1:  13% 40/300 [08:50<55:17, 12.76s/it]\u001b[32m[1222 12:24:16 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:08:54 -----\n",
            "universal: epoch1:  14% 41/300 [08:55<45:14, 10.48s/it]\u001b[32m[1222 12:24:19 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1224)\n",
            "\u001b[32m[1222 12:24:36 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 17\n",
            "\u001b[32m[1222 12:24:38 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:09:16 -----\n",
            "universal: epoch1:  14% 42/300 [09:17<59:55, 13.94s/it]\u001b[32m[1222 12:24:42 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:09:20 -----\n",
            "universal: epoch1:  14% 43/300 [09:21<46:56, 10.96s/it]\u001b[32m[1222 12:24:44 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1224)\n",
            "\u001b[32m[1222 12:25:01 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 17\n",
            "\u001b[32m[1222 12:25:02 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:09:40 -----\n",
            "universal: epoch1:  15% 44/300 [09:41<58:33, 13.72s/it]\u001b[32m[1222 12:25:05 @train.py:104]\u001b[0m Task02_Heart self.trainQueue size = 0, filling....(start time:20231222_1225)\n",
            "\u001b[32m[1222 12:25:06 @train.py:109]\u001b[0m Task02_Heart time to fill self.trainQueue: 1\n",
            "\u001b[32m[1222 12:25:07 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:09:44 -----\n",
            "universal: epoch1:  15% 45/300 [09:46<46:23, 10.91s/it]\u001b[32m[1222 12:25:09 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1225)\n",
            "\u001b[32m[1222 12:25:24 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 15\n",
            "\u001b[32m[1222 12:25:25 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:10:02 -----\n",
            "universal: epoch1:  15% 46/300 [10:04<55:46, 13.18s/it]\u001b[32m[1222 12:25:29 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:10:06 -----\n",
            "universal: epoch1:  16% 47/300 [10:08<43:29, 10.31s/it]\u001b[32m[1222 12:25:31 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1225)\n",
            "\u001b[32m[1222 12:25:49 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 18\n",
            "\u001b[32m[1222 12:25:50 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:10:28 -----\n",
            "universal: epoch1:  16% 48/300 [10:29<57:27, 13.68s/it]\u001b[32m[1222 12:25:53 @train.py:104]\u001b[0m Task02_Heart self.trainQueue size = 0, filling....(start time:20231222_1225)\n",
            "\u001b[32m[1222 12:25:59 @train.py:109]\u001b[0m Task02_Heart time to fill self.trainQueue: 6\n",
            "\u001b[32m[1222 12:26:00 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:10:38 -----\n",
            "universal: epoch1:  16% 49/300 [10:39<52:40, 12.59s/it]\u001b[32m[1222 12:26:03 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1226)\n",
            "\u001b[32m[1222 12:26:12 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 9\n",
            "\u001b[32m[1222 12:26:13 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:10:51 -----\n",
            "universal: epoch1:  17% 50/300 [10:52<52:56, 12.71s/it]\u001b[32m[1222 12:26:17 @train.py:311]\u001b[0m ----- Task02_Heart, train epoch 1 time elapsed:hr:min:sec, 0:10:55 -----\n",
            "universal: epoch1:  17% 51/300 [10:56<41:50, 10.08s/it]\u001b[32m[1222 12:26:20 @train.py:104]\u001b[0m Task04_Hippocampus self.trainQueue size = 0, filling....(start time:20231222_1226)\n",
            "\u001b[32m[1222 12:26:35 @train.py:109]\u001b[0m Task04_Hippocampus time to fill self.trainQueue: 15\n",
            "\u001b[32m[1222 12:26:37 @train.py:311]\u001b[0m ----- Task04_Hippocampus, train epoch 1 time elapsed:hr:min:sec, 0:11:14 -----\n",
            "universal: epoch1:  17% 52/300 [11:16<53:28, 12.94s/it]\u001b[32m[1222 12:26:39 @train.py:104]\u001b[0m Task02_Heart self.trainQueue size = 0, filling....(start time:20231222_1226)\n",
            "universal: epoch1:  17% 52/300 [11:21<54:08, 13.10s/it]Exception ignored in: <generator object tqdm.__iter__ at 0x7e0b6ce6d000>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1197, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1303, in close\n",
            "    self.display(pos=0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1496, in display\n",
            "    self.sp(self.__str__() if msg is None else msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 462, in print_status\n",
            "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 455, in fp_write\n",
            "    fp.write(str(s))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/utils.py\", line 195, in inner\n",
            "    return func(*args, **kwargs)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/train_model_wt_adapters.py\", line 165, in <module>\n",
            "    train.train(args, tasks_archive, model)\n",
            "  File \"/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/train.py\", line 277, in train\n",
            "    (batchImg, batchLabel, batchWeight, batchAugs) = tb_loaders[config.task_idx].gen_batch(config.batch_size, config.patch_size)\n",
            "  File \"/content/3D-Universal-U-Net-for-Multi-Domain-Medical-Image-Segmentation/train.py\", line 106, in gen_batch\n",
            "    time.sleep(1)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}